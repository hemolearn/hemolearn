{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Real fMRI data example\n\nExample to recover the different neural temporal activities, the associated\nfunctional networks maps and the HRFs per ROIs in the fMRI data, on the ADHD\ndataset resting-state.\n    :depth: 1\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Hamza Cherkaoui <hamza.cherkaoui@inria.fr>\n# License: BSD (3-clause)\n\nimport os\nimport time\nimport argparse\nimport pickle\nimport numpy as np\nfrom nilearn import datasets\n\nfrom hemolearn import SLRDA\nfrom hemolearn.utils import (fmri_preprocess,\n                             sort_atoms_by_explained_variances)\nfrom hemolearn.plotting import (plotting_spatial_comp, plotting_temporal_comp,\n                                plotting_obj_values, plotting_hrf,\n                                plotting_hrf_stats)\n\n\nif __name__ == '__main__':\n\n    parser = argparse.ArgumentParser(\n        description=__doc__)\n    parser.add_argument('--n-atoms', type=int, default=30,\n                        help='Number of atoms to decompose the fMRI data.')\n    parser.add_argument('--max-iter', type=int, default=100,\n                        help='Max number of iterations to train the '\n                        'learnable networks.')\n    parser.add_argument('--lmbd', type=float, default=0.5,\n                        help='Set the regularisation parameter for the '\n                        'experiment.')\n    parser.add_argument('--seed', type=int, default=None,\n                        help='Set the seed for the experiment. Can be used '\n                        'for debug or to freeze experiments.')\n    parser.add_argument('--plot-dir', type=str, default='results_adhd',\n                        help='Set the name of the plot directory.')\n    parser.add_argument('--cpu', type=int, default=1,\n                        help='Set the number of CPU for the decomposition.')\n    parser.add_argument('--verbose', type=int, default=0,\n                        help='Verbosity level.')\n    args = parser.parse_args()\n\n    if not os.path.exists(args.plot_dir):\n        os.makedirs(args.plot_dir)\n\n    TR = 2.0\n    adhd_dataset = datasets.fetch_adhd(n_subjects=1)\n    func_fname = adhd_dataset.func[0]\n    confound_fname = adhd_dataset.confounds[0]\n    X, _, _ = fmri_preprocess(func_fname, smoothing_fwhm=6.0, standardize=True,\n                            detrend=True, low_pass=0.1, high_pass=0.01, t_r=TR,\n                            memory='__cache__', verbose=0,\n                            confounds=confound_fname)\n\n    seed = np.random.randint(0, 1000) if args.seed is None else args.seed\n    print(f'Seed used = {seed}')\n\n    slrda = SLRDA(n_atoms=args.n_atoms, t_r=TR, n_times_atom=30,\n                hrf_model='scaled_hrf', lbda=args.lmbd, max_iter=args.max_iter,\n                eps=1.0e-3, deactivate_v_learning=False,\n                prox_u='l1-positive-simplex', raise_on_increase=True,\n                random_state=seed, n_jobs=args.cpu, cache_dir='__cache__',\n                nb_fit_try=1, verbose=args.verbose)\n\n    t0 = time.time()\n    slrda.fit(X)\n    delta_t = time.strftime(\"%H h %M min %S s\", time.gmtime(time.time() - t0))\n    print(\"Fitting done in {}\".format(delta_t))\n\n    hrf_ref = slrda.v_init\n    roi_label_from_hrf_idx = slrda.roi_label_from_hrf_idx\n    pobj, times, a_hat = slrda.lobj, slrda.ltime, slrda.a_hat\n    v_hat = slrda.v_hat\n    u_hat, z_hat, variances = sort_atoms_by_explained_variances(slrda.u_hat,\n                                                                slrda.z_hat,\n                                                                slrda.v_hat,\n                                                                slrda.hrf_rois)\n\n    res = dict(pobj=pobj, times=times, u_hat=u_hat, v_hat=v_hat, z_hat=z_hat)\n    filename = os.path.join(args.plot_dir, \"results.pkl\")\n    print(\"Pickling results under '{0}'\".format(filename))\n    with open(filename, \"wb\") as pfile:\n        pickle.dump(res, pfile)\n\n    plotting_spatial_comp(u_hat, variances, slrda.masker_,\n                          plot_dir=args.plot_dir, perc_voxels_to_retain=0.1,\n                          verbose=True)\n    plotting_temporal_comp(z_hat, variances, TR, plot_dir=args.plot_dir,\n                           verbose=True)\n    plotting_obj_values(times, pobj, plot_dir=args.plot_dir, verbose=True)\n    plotting_hrf(v_hat, TR, roi_label_from_hrf_idx, hrf_ref=hrf_ref,\n                 normalized=True, plot_dir=args.plot_dir, verbose=True)\n    plotting_hrf_stats(v_hat, TR, roi_label_from_hrf_idx, hrf_ref=None,\n                       stat_type='tp', plot_dir=args.plot_dir, verbose=True)\n    plotting_hrf_stats(v_hat, TR, roi_label_from_hrf_idx, hrf_ref=None,\n                       stat_type='fwhm', plot_dir=args.plot_dir, verbose=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}